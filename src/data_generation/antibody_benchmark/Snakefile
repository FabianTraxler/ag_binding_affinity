import os
import pandas as pd

from os.path import join
from pathlib import Path

DATASET_NAME = "antibody_benchmark"

project_root = Path(workflow.basedir).parents[2] # two directories above - absolute paths not working
resource_folder = os.path.join(project_root, "resources")
results_folder = os.path.join(project_root, "results")

dataset_resource_folder = os.path.join(resource_folder, DATASET_NAME)
dataset_results_folder = os.path.join(results_folder, DATASET_NAME)

pdb_relaxed_folder = os.path.join(dataset_results_folder, "pdbs_relaxed")
pdb_bound_folder = os.path.join(dataset_results_folder, "pdbs_bound")
pdb_folder = os.path.join(dataset_resource_folder, "pdbs")

def gater_pdb_ids(wildcards):
    
    metadata_fn = checkpoints.clean_metadata.get(**wildcards).output[0]
    df = pd.read_csv(metadata_fn)
    # pdb_id = glob_wildcards(f"{pdb_folder}/{{pdb_id}}_r_b.pdb").pdb_id
    return expand("{pdb_folder}/{pdb_id}.pdb", pdb_folder=[pdb_bound_folder, pdb_relaxed_folder], pdb_id=df["pdb"].str.upper().tolist())


rule all:
    input:
        gater_pdb_ids,
        join(dataset_results_folder, "benchmark.csv")

rule download_repo:
    output:
        join(dataset_resource_folder, "README.md")
    params:
        resource_folder=resource_folder,
    shell:
        "scripts/download_repo.sh {params.resource_folder}"


rule download_metadata:
    input:
        rules.download_repo.output
    output:
        join(dataset_resource_folder, "antibody_benchmark_cases.xlsx")
    params:
        dataset_resource_folder=dataset_resource_folder
    shell:
        "scripts/download_metadata.sh {params.dataset_resource_folder}"


checkpoint clean_metadata:
    input:
        xlsx=rules.download_metadata.output[0],
        pdb_dir=directory(abdb_resource_pdb_folder)
    output:
        csv=join(dataset_results_folder, "benchmark.csv")
    conda:
        "ag_binding_diffusion3"  # conda name env loading requires snakemake >v7.30.1
    script:
        "scripts/clean_metadata.py"


rule bind_structures:
    input:
        antibody=join(dataset_resource_folder, "pdbs/{pdb_id}_r_b.pdb"),
        antigen=join(dataset_resource_folder, "pdbs/{pdb_id}_l_b.pdb"),
        csv=rules.clean_metadata.output.csv
    output:
        join(pdb_bound_folder, "{pdb_id}.pdb")
    # conda:
    #     join(project_root, "envs/generation_environment.yml")
    run:
        import pandas as pd

        import subprocess

        df = pd.read_csv(input.csv, index_col="pdb")
        chain_infos = eval(df.loc[wildcards.pdb_id.lower(), "chain_infos"])  # only for replacement

        replace_chain_commands="| ".join([f"pdb_rplchain -{old_chain}:{new_chain}" for old_chain, new_chain in chain_infos.items()])
        cmd = f"cat {input.antibody} {input.antigen} | pdb_sort | pdb_tidy | pdb_delhetatm | {replace_chain_commands} > {output}"
        print(cmd)
        subprocess.run(cmd, shell=True, check=True)


rule relax_structures:
    input:
        join(pdb_bound_folder, "{pdb_id}.pdb")
    output:
        join(pdb_relaxed_folder, "{pdb_id}.pdb")
    conda:
        join(project_root, "envs/generation_environment.yml")
    script:
        "../scripts/relax.py"
