{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": "WARNING:root:Pytorch pre-release version 1.12.1.post201 - assuming intent to test it\n"
                }
            ],
            "source": "from typing import Dict, List, Tuple, Union, Optional, Callable\n\nimport sys\nimport wandb\nimport numpy as np\nimport math\nimport pandas as pd\nimport os\nfrom copy import deepcopy\nfrom argparse import Namespace\nfrom pathlib import Path\nimport logging\nimport torch\nfrom scipy import stats\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader as DL_torch\nfrom torch_geometric.data import DataLoader\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\nfrom functools import partial\n# import pdb\n\nfrom abag_affinity.dataset import AffinityDataset\nfrom abag_affinity.dataset.advanced_data_utils import complexes_from_dms_datasets, get_bucket_dataloader, load_datasets\nfrom abag_affinity.model import AffinityGNN, TwinWrapper\nfrom abag_affinity.train.wandb_config import configure\nfrom abag_affinity.utils.config import get_data_paths, read_config\nfrom abag_affinity.utils.visualize import plot_correlation\nfrom abag_affinity.utils.argparse_utils import read_args_from_file, parse_args\nfrom abag_affinity.train.utils import load_model\n%load_ext autoreload\n%autoreload 2"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "trusted": true
            },
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'list' object has no attribute 'split'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m use_cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m train_data, val_datas \u001b[38;5;241m=\u001b[39m \u001b[43mload_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(train_data\u001b[38;5;241m.\u001b[39mnum_features, train_data\u001b[38;5;241m.\u001b[39mnum_edge_features, args\u001b[38;5;241m.\u001b[39mtarget_dataset, args, device)\n",
                        "File \u001b[0;32m~/Documents/workspace/ag_binding_affinity/src/abag_affinity/dataset/advanced_data_utils.py:260\u001b[0m, in \u001b[0;36mload_datasets\u001b[0;34m(config, dataset, validation_set, args, validation_size, only_neglogkd_samples)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_datasets\u001b[39m(config: Dict, dataset: \u001b[38;5;28mstr\u001b[39m, validation_set: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m    241\u001b[0m                   args: Namespace, validation_size: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m    242\u001b[0m                   only_neglogkd_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[1;32m    243\u001b[0m     AffinityDataset, List[AffinityDataset]]:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;124;03m\"\"\" Get train and validation datasets for a specific dataset and data type\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    1. Get train and validation splits\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124;03m        Tuple: Train and validation dataset\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m     dataset_name, loss_types \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# We missuse the data_type to allow setting different losses\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# The losses used for this dataset come after a # seperated by a comma, when multiple losses are used\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;66;03m# Optionally, the losses can contain some weight using -\u001b[39;00m\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;66;03m# E.g. data_type = relative#l2-1,l1-0.1,relative_l1-2,relative_2-0.1,relative_ce-1\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelative\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m loss_types \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m only_neglogkd_samples:\n",
                        "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
                    ]
                }
            ],
            "source": "args_file = \"base_args.txt\"\n\nsys.argv = sys.argv[:1]\nargs = parse_args(args_file=args_file)\n\nconfig = read_config(args.config_file)\n\nuse_cuda = False\ndevice = 'cpu'\n\ntrain_data, val_datas = load_datasets(config, args.target_dataset, args.validation_set, args)\nmodel = load_model(train_data.num_features, train_data.num_edge_features, args.target_dataset, args, device)\n\n# wandb_benchmark_log = run_and_log_benchmarks(model, args, wandb_inst)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "trusted": true
            },
            "outputs": [],
            "source": "args = parse_args(artifical_args={\"args_file\": 'base_args.txt'})\n\nconfig = read_config(args.config_file)\n\nuse_cuda = False\ndevice = 'cpu'\n\ntrain_data, val_datas = load_datasets(config, args.target_dataset, args.validation_set, args)\nmodel = load_model(train_data.num_features, train_data.num_edge_features, args.target_dataset, args, device)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}