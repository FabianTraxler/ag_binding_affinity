{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "051b1b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, List, Tuple, Union, Optional, Callable\n",
    "\n",
    "import sys\n",
    "import wandb\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import torch\n",
    "from scipy import stats\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader as DL_torch\n",
    "from torch_geometric.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from functools import partial\n",
    "# import pdb\n",
    "\n",
    "from abag_affinity.dataset import AffinityDataset\n",
    "from abag_affinity.dataset.advanced_data_utils import complexes_from_dms_datasets, get_bucket_dataloader, load_datasets\n",
    "from abag_affinity.model import AffinityGNN, TwinWrapper\n",
    "from abag_affinity.train.wandb_config import configure\n",
    "from abag_affinity.utils.config import get_data_paths, read_config\n",
    "from abag_affinity.utils.visualize import plot_correlation\n",
    "from abag_affinity.utils.argparse_utils import read_args_from_file, parse_args\n",
    "from abag_affinity.train.utils import load_model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c72eae8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Number of closest nodes does not match number of residues",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/mihail/miniconda3/envs/ag_binding_diffusion3/lib/python3.8/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/mihail/miniconda3/envs/ag_binding_diffusion3/lib/python3.8/site-packages/multiprocess/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/home/mihail/miniconda3/envs/ag_binding_diffusion3/lib/python3.8/site-packages/pathos/helpers/mp_helper.py\", line 15, in <lambda>\n    func = lambda args: f(*args)\n  File \"/home/mihail/miniconda3/envs/ag_binding_diffusion3/lib/python3.8/site-packages/parallel.py\", line 85, in submit_helper\n    raise e\n  File \"/home/mihail/miniconda3/envs/ag_binding_diffusion3/lib/python3.8/site-packages/parallel.py\", line 79, in submit_helper\n    return function(*inputs)\n  File \"/home/mihail/Documents/workspace/ag_binding_affinity/src/abag_affinity/dataset/data_loader.py\", line 338, in preload_graph_dict\n    graph_dict = load_graph_dict(row, self.dataset_name, self.config, self.interface_dir,\n  File \"/home/mihail/Documents/workspace/ag_binding_affinity/src/abag_affinity/dataset/utils.py\", line 189, in load_graph_dict\n    graph_dict = get_graph_dict(pdb_id, pdb_file_path, embeddings, node_type, neg_log_kd, e_value, distance_cutoff=max_edge_distance)\n  File \"/home/mihail/Documents/workspace/ag_binding_affinity/src/abag_affinity/dataset/utils.py\", line 98, in get_graph_dict\n    assert len(closest_nodes) == len(residue_infos), \"Number of closest nodes does not match number of residues\"\nAssertionError: Number of closest nodes does not match number of residues\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m use_cuda \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m train_data, val_datas \u001b[38;5;241m=\u001b[39m \u001b[43mload_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(train_data\u001b[38;5;241m.\u001b[39mnum_features, train_data\u001b[38;5;241m.\u001b[39mnum_edge_features, args\u001b[38;5;241m.\u001b[39mtarget_dataset, args, device)\n",
      "File \u001b[0;32m~/Documents/workspace/ag_binding_affinity/src/abag_affinity/dataset/advanced_data_utils.py:299\u001b[0m, in \u001b[0;36mload_datasets\u001b[0;34m(config, dataset, validation_set, args, validation_size, only_neglogkd_samples)\u001b[0m\n\u001b[1;32m    277\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet dataLoader for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m train_data \u001b[38;5;241m=\u001b[39m AffinityDataset(config, args\u001b[38;5;241m.\u001b[39mrelaxed_pdbs, dataset_name, loss_types,\n\u001b[1;32m    279\u001b[0m                              train_ids,\n\u001b[1;32m    280\u001b[0m                              node_type\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnode_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m                              only_neglogkd_samples\u001b[38;5;241m=\u001b[39monly_neglogkd_samples,\n\u001b[1;32m    297\u001b[0m                              )\n\u001b[0;32m--> 299\u001b[0m val_datas \u001b[38;5;241m=\u001b[39m [AffinityDataset(config, relaxed, dataset_name, loss_types,  \u001b[38;5;66;03m# TODO @marco val should be done with the same loss as training, right?\u001b[39;00m\n\u001b[1;32m    300\u001b[0m                              val_ids,\n\u001b[1;32m    301\u001b[0m                              node_type\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnode_type,\n\u001b[1;32m    302\u001b[0m                              max_nodes\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_num_nodes,\n\u001b[1;32m    303\u001b[0m                              interface_distance_cutoff\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minterface_distance_cutoff,\n\u001b[1;32m    304\u001b[0m                              interface_hull_size\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39minterface_hull_size,\n\u001b[1;32m    305\u001b[0m                              max_edge_distance\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_edge_distance,\n\u001b[1;32m    306\u001b[0m                              pretrained_model\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mpretrained_model,\n\u001b[1;32m    307\u001b[0m                              scale_values\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mscale_values,\n\u001b[1;32m    308\u001b[0m                              scale_min\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mscale_min,\n\u001b[1;32m    309\u001b[0m                              scale_max\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mscale_max,\n\u001b[1;32m    310\u001b[0m                              relative_data\u001b[38;5;241m=\u001b[39mrelative_data,\n\u001b[1;32m    311\u001b[0m                              save_graphs\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39msave_graphs,\n\u001b[1;32m    312\u001b[0m                              force_recomputation\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mforce_recomputation,\n\u001b[1;32m    313\u001b[0m                              preprocess_data\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mpreprocess_graph,\n\u001b[1;32m    314\u001b[0m                              preprocessed_to_scratch\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mpreprocessed_to_scratch,\n\u001b[1;32m    315\u001b[0m                              num_threads\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnum_workers,\n\u001b[1;32m    316\u001b[0m                              load_embeddings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39membeddings_type \u001b[38;5;28;01melse\u001b[39;00m (args\u001b[38;5;241m.\u001b[39membeddings_type, args\u001b[38;5;241m.\u001b[39membeddings_path),\n\u001b[1;32m    317\u001b[0m                              only_neglogkd_samples\u001b[38;5;241m=\u001b[39monly_neglogkd_samples,\n\u001b[1;32m    318\u001b[0m                              )\n\u001b[1;32m    319\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m relaxed \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mbool\u001b[39m(args\u001b[38;5;241m.\u001b[39mrelaxed_pdbs)]\n\u001b[1;32m    320\u001b[0m              ]  \u001b[38;5;66;03m# TODO disabling , not args.relaxed_pdbs for now. Enable once we generated all relaxed data\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_data, val_datas\n",
      "File \u001b[0;32m~/Documents/workspace/ag_binding_affinity/src/abag_affinity/dataset/advanced_data_utils.py:299\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    277\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet dataLoader for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    278\u001b[0m train_data \u001b[38;5;241m=\u001b[39m AffinityDataset(config, args\u001b[38;5;241m.\u001b[39mrelaxed_pdbs, dataset_name, loss_types,\n\u001b[1;32m    279\u001b[0m                              train_ids,\n\u001b[1;32m    280\u001b[0m                              node_type\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnode_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m                              only_neglogkd_samples\u001b[38;5;241m=\u001b[39monly_neglogkd_samples,\n\u001b[1;32m    297\u001b[0m                              )\n\u001b[0;32m--> 299\u001b[0m val_datas \u001b[38;5;241m=\u001b[39m [\u001b[43mAffinityDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelaxed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO @marco val should be done with the same loss as training, right?\u001b[39;49;00m\n\u001b[1;32m    300\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mval_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnode_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_num_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                             \u001b[49m\u001b[43minterface_distance_cutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface_distance_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                             \u001b[49m\u001b[43minterface_hull_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface_hull_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mmax_edge_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_edge_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpretrained_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretrained_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mscale_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mscale_min\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_min\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mscale_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mrelative_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelative_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                             \u001b[49m\u001b[43msave_graphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_graphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mforce_recomputation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforce_recomputation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpreprocess_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mpreprocessed_to_scratch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessed_to_scratch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mload_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m                             \u001b[49m\u001b[43monly_neglogkd_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43monly_neglogkd_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m relaxed \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mbool\u001b[39m(args\u001b[38;5;241m.\u001b[39mrelaxed_pdbs)]\n\u001b[1;32m    320\u001b[0m              ]  \u001b[38;5;66;03m# TODO disabling , not args.relaxed_pdbs for now. Enable once we generated all relaxed data\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_data, val_datas\n",
      "File \u001b[0;32m~/Documents/workspace/ag_binding_affinity/src/abag_affinity/dataset/data_loader.py:166\u001b[0m, in \u001b[0;36mAffinityDataset.__init__\u001b[0;34m(self, config, is_relaxed, dataset_name, loss_criterion, pdb_ids, node_type, max_nodes, interface_distance_cutoff, interface_hull_size, max_edge_distance, pretrained_model, scale_values, scale_min, scale_max, relative_data, save_graphs, force_recomputation, preprocess_data, preprocessed_to_scratch, num_threads, load_embeddings, only_neglogkd_samples)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_data:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelaxed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# Copy embeddings to fast scratch space\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocessed_to_scratch:\n",
      "File \u001b[0;32m~/Documents/workspace/ag_binding_affinity/src/abag_affinity/dataset/data_loader.py:348\u001b[0m, in \u001b[0;36mAffinityDataset.preprocess\u001b[0;34m(self, relaxed)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;124;03m\"\"\" Function to get graph dict and store to disc. Used to parallelize preprocessing\u001b[39;00m\n\u001b[1;32m    329\u001b[0m \n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03m        None\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m     graph_dict \u001b[38;5;241m=\u001b[39m load_graph_dict(row, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface_dir,\n\u001b[1;32m    339\u001b[0m                                  node_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_type,\n\u001b[1;32m    340\u001b[0m                                  interface_distance_cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterface_distance_cutoff,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    346\u001b[0m                                  relaxed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_relaxed\n\u001b[1;32m    347\u001b[0m                                 )\n\u001b[0;32m--> 348\u001b[0m \u001b[43msubmit_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreload_graph_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_dicts2process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrained_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepRefine\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreprocessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(deeprefine_graphs2process)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m DeepRefine graphs with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m threads\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ag_binding_diffusion3/lib/python3.8/site-packages/parallel.py:60\u001b[0m, in \u001b[0;36msubmit_jobs\u001b[0;34m(function, inputs, num_threads)\u001b[0m\n\u001b[1;32m     53\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m [(function,) \u001b[38;5;241m+\u001b[39m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m     55\u001b[0m     res \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mamap(\n\u001b[1;32m     56\u001b[0m         submit_helper,\n\u001b[1;32m     57\u001b[0m         inputs,\n\u001b[1;32m     58\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mres\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSequential Mode.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ag_binding_diffusion3/lib/python3.8/site-packages/multiprocess/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mAssertionError\u001b[0m: Number of closest nodes does not match number of residues"
     ]
    }
   ],
   "source": [
    "args_file = \"base_args.txt\"\n",
    "\n",
    "sys.argv = sys.argv[:1]\n",
    "args = parse_args(args_file=args_file)\n",
    "\n",
    "config = read_config(args.config_file)\n",
    "\n",
    "use_cuda = False\n",
    "device = 'cpu'\n",
    "\n",
    "train_data, val_datas = load_datasets(config, args.target_dataset, args.validation_set, args)\n",
    "model = load_model(train_data.num_features, train_data.num_edge_features, args.target_dataset, args, device)\n",
    "\n",
    "# wandb_benchmark_log = run_and_log_benchmarks(model, args, wandb_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a14197c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--target_dataset TARGET_DATASET]\n",
      "                             [-tld TRANSFER_LEARNING_DATASETS [TRANSFER_LEARNING_DATASETS ...]]\n",
      "                             [--relaxed_pdbs {True,False,both}]\n",
      "                             [-t {bucket_train,train_transferlearnings_validate_target}]\n",
      "                             [--bucket_size_mode {min,geometric_mean,double_geometric_mean}]\n",
      "                             [-m {,DeepRefine,Binding_DDG,IPA,Diffusion}]\n",
      "                             [--fine_tune FINE_TUNE]\n",
      "                             [--load_pretrained_weights]\n",
      "                             [--training_set_spikein TRAINING_SET_SPIKEIN]\n",
      "                             [-b BATCH_SIZE] [-e MAX_EPOCHS]\n",
      "                             [-lr LEARNING_RATE] [-p PATIENCE]\n",
      "                             [--lr_scheduler {constant,plateau,exponential}]\n",
      "                             [--stop_at_learning_rate STOP_AT_LEARNING_RATE]\n",
      "                             [--lr_decay_factor LR_DECAY_FACTOR]\n",
      "                             [-n {residue,atom}]\n",
      "                             [--max_num_nodes MAX_NUM_NODES]\n",
      "                             [--interface_distance_cutoff INTERFACE_DISTANCE_CUTOFF]\n",
      "                             [--interface_hull_size INTERFACE_HULL_SIZE]\n",
      "                             [--scale_values] [--scale_min SCALE_MIN]\n",
      "                             [--scale_max SCALE_MAX]\n",
      "                             [--max_edge_distance MAX_EDGE_DISTANCE]\n",
      "                             [--add_neglogkd_labels_dataset ADD_NEGLOGKD_LABELS_DATASET]\n",
      "                             [--layer_type {GAT,GCN}]\n",
      "                             [--gnn_type {proximity,guided,identity,egnn}]\n",
      "                             [--num_gnn_layers NUM_GNN_LAYERS]\n",
      "                             [--attention_heads ATTENTION_HEADS]\n",
      "                             [--channel_halving] [--channel_doubling]\n",
      "                             [--aggregation_method {max,sum,mean,attention,fixed_size,edge,interface_sum,interface_mean,interface_size}]\n",
      "                             [--nonlinearity {relu,leaky,gelu,silu}]\n",
      "                             [--num_fc_layers NUM_FC_LAYERS]\n",
      "                             [--fc_size_halving]\n",
      "                             [--dms_output_layer_type {identity,bias_only,regression,regression_sigmoid,positive_regression,positive_regression_sigmoid,mlp}]\n",
      "                             [-wdb] [--wandb_mode {online,offline}]\n",
      "                             [--wandb_name WANDB_NAME]\n",
      "                             [--wandb_user WANDB_USER]\n",
      "                             [--model_path MODEL_PATH] [--init_sweep]\n",
      "                             [--sweep_config SWEEP_CONFIG]\n",
      "                             [--sweep_id SWEEP_ID] [--sweep_runs SWEEP_RUNS]\n",
      "                             [-w NUM_WORKERS] [--cross_validation]\n",
      "                             [--number_cv_splits NUMBER_CV_SPLITS]\n",
      "                             [-v {0,1,2,3,4}] [-c CONFIG_FILE] [--verbose]\n",
      "                             [--preprocess_graph]\n",
      "                             [--preprocessed_to_scratch PREPROCESSED_TO_SCRATCH]\n",
      "                             [--save_graphs] [--force_recomputation]\n",
      "                             [--shuffle] [--test] [--cuda] [--tqdm_output]\n",
      "                             [--args_file ARGS_FILE]\n",
      "                             [--embeddings_path EMBEDDINGS_PATH]\n",
      "                             [--embeddings_type {,rf,of}] [--seed SEED]\n",
      "                             [--debug] [--weight_decay WEIGHT_DECAY]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: args_file\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(artifical_args={\"args_file\": 'base_args.txt'})\n",
    "\n",
    "config = read_config(args.config_file)\n",
    "\n",
    "use_cuda = False\n",
    "device = 'cpu'\n",
    "\n",
    "train_data, val_datas = load_datasets(config, args.target_dataset, args.validation_set, args)\n",
    "model = load_model(train_data.num_features, train_data.num_edge_features, args.target_dataset, args, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
